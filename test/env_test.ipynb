{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from envs.make_envs import make_unity_gym\n",
    "from mlagents_envs.environment import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to Unity environment with package version 2.3.0-exp.4 and communication version 1.5.0\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment('../envs/pushblock/mac_build.app')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected new brain: PushBlockCollab?team=0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PushBlockCollab?team=0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviour_names = [\n",
    "            name for name in env.behavior_specs.keys()]\n",
    "behaviour_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for agent_id, action in {0:1, 1:2}.items():\n",
    "            behaviour_name = self._agent_id_to_behaviour_name[agent_id]\n",
    "            action = np.array(action).reshape((1, 1))\n",
    "\n",
    "            action_tuple = ActionTuple()\n",
    "            action_tuple.add_discrete(action)\n",
    "            self._env.set_action_for_agent(behaviour_name, agent_id, action_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.base_env import BaseEnv, DecisionSteps, TerminalSteps, ActionTuple\n",
    "\n",
    "def _single_step(self, info_dict):\n",
    "        obs_dict, reward_dict, done_dict = {}, {}, {}\n",
    "        vec_obs_size = self._get_vec_obs_size()\n",
    "        n_vis_obs = self._get_n_vis_obs()\n",
    "\n",
    "        for behaviour_name, info in info_dict.items():\n",
    "            default_observation = None\n",
    "            if self._allow_multiple_obs:\n",
    "                visual_obs = self._get_vis_obs_list(info)\n",
    "                visual_obs_list = []\n",
    "                for obs in visual_obs:\n",
    "                    visual_obs_list.append(self._preprocess_single(obs[0]))\n",
    "                default_observation = visual_obs_list\n",
    "                if vec_obs_size[behaviour_name] >= 1:\n",
    "                    default_observation.append(\n",
    "                        self._get_vector_obs(info))\n",
    "            else:\n",
    "                if n_vis_obs[behaviour_name] >= 1:\n",
    "                    visual_obs = self._get_vis_obs_list(info)\n",
    "                    default_observation = self._preprocess_single(visual_obs[0][0])\n",
    "                else:\n",
    "                    obs_dict.update(self._get_vector_obs(info))\n",
    "\n",
    "            if n_vis_obs[behaviour_name] >= 1:\n",
    "                visual_obs = self._get_vis_obs_list(info)\n",
    "                self.visual_obs = self._preprocess_single(visual_obs[0][0])\n",
    "\n",
    "            done = isinstance(info, TerminalSteps)\n",
    "            for agent_id in info.agent_id:\n",
    "                # Add reward and done\n",
    "                agent_index = info.agent_id_to_index[agent_id]\n",
    "                reward_dict[agent_id] = info.reward[agent_index]\n",
    "                done_dict[agent_id] = done\n",
    "                if default_observation is not None:\n",
    "                    obs_dict[agent_id] = default_observation\n",
    "\n",
    "        return (obs_dict, reward_dict, done_dict, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_vis_obs_list(\n",
    "    self, step_result: Union[DecisionSteps, TerminalSteps]\n",
    ") -> List[np.ndarray]:\n",
    "    result: List[np.ndarray] = []\n",
    "    for obs in step_result.obs:\n",
    "        if len(obs.shape) == 4:\n",
    "            result.append(obs)\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
